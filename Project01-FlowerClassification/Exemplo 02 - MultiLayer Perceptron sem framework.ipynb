{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b92ab90",
   "metadata": {},
   "source": [
    "# MultiLayer Perceptron sem Framework\n",
    "\n",
    "#### Definição do problema\n",
    "- **Objetivo**: identificar se uma pessoa é atleta ou não;\n",
    "- **Features**: altura e peso de uma pessoa;\n",
    "- **Saída**: 1 (é atleta) ou 0 (não é atleta).\n",
    "\n",
    "#### Estrutura da MLP\n",
    "- **Camada de entrada**: 2 neurônios (altura e peso);\n",
    "- **Camada oculta**: 3 neurônios (com função de ativação ReLU);\n",
    "- **Camada de saída**: 1 neurônio (com função de ativação Sigmoid).\n",
    "\n",
    "##### Passos\n",
    "0. **Inicializar os dados de entrada**: definir os dados para treinamento e os rótulos com as respostas;\n",
    "1. **Inicializar os pesos e bias**: pesos e bias com valores aleatórios pequenos;\n",
    "1. **Forward Propagation**: propagar a entrada até a saída;\n",
    "1. **Calcular o erro**: usar erro quadrático médio (MSE) ou entropia cruzada;\n",
    "1. **Backward Propagation**: calcular os gradientes e ajustar pesos e bias;\n",
    "1. **Loop de treinamento**: repetir várias vezes para minimizar o erro.\n",
    "\n",
    "<center><image src=\"../Imagens/exemploMLP_3_perceptrons_na_camada_oculta.jpg\" width=\"400\"></image></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43298bb",
   "metadata": {},
   "source": [
    "### Passo 0: Dados e rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112c0808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dados de entrada (altura, peso)\n",
    "X = np.array([\n",
    "    [1.70, 65],\n",
    "    [1.80, 80],\n",
    "    [1.60, 50],\n",
    "    [1.90, 90]\n",
    "])\n",
    "\n",
    "# Rótulos corretos (y) - só para quando for calcular o erro\n",
    "y = np.array([\n",
    "    [1],\n",
    "    [1],\n",
    "    [0],\n",
    "    [1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7e69f8",
   "metadata": {},
   "source": [
    "### Passo 1: Inicializar os pesos e bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d915e887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos W1 (entrada -> camada oculta):\n",
      "[[ 0.00496714 -0.00138264  0.00647689]\n",
      " [ 0.0152303  -0.00234153 -0.00234137]]\n",
      "\n",
      "Bias b1 (camada oculta):\n",
      "[[0. 0. 0.]]\n",
      "\n",
      "Pesos W2 (camada oculta -> saída):\n",
      "[[ 0.01579213]\n",
      " [ 0.00767435]\n",
      " [-0.00469474]]\n",
      "\n",
      "Bias b2 (saída):\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "# Fixar a semente para reprodutibilidade, ou seja, garante o retorno do mesmo número aleatório\n",
    "np.random.seed(42)\n",
    "\n",
    "# Inicializar pesos e bias\n",
    "\n",
    "# W1: pesos da camada de entrada para a camada oculta\n",
    "# 2 entradas (altura, peso) → 3 neurônios ocultos\n",
    "W1 = np.random.randn(2, 3) * 0.01\n",
    "\n",
    "# b1: bias para cada um dos 3 neurônios ocultos\n",
    "b1 = np.zeros((1, 3))\n",
    "\n",
    "# W2: pesos da camada oculta para a camada de saída\n",
    "# 3 neurônios ocultos → 1 saída\n",
    "W2 = np.random.randn(3, 1) * 0.01\n",
    "\n",
    "# b2: bias para a saída\n",
    "b2 = np.zeros((1, 1))\n",
    "\n",
    "# Mostrar os valores iniciais\n",
    "print(\"Pesos W1 (entrada -> camada oculta):\")\n",
    "print(W1)\n",
    "print(\"\\nBias b1 (camada oculta):\")\n",
    "print(b1)\n",
    "print(\"\\nPesos W2 (camada oculta -> saída):\")\n",
    "print(W2)\n",
    "print(\"\\nBias b2 (saída):\")\n",
    "print(b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e0a20",
   "metadata": {},
   "source": [
    "### Passo 2: Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98c49157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saída da camada oculta (a1):\n",
      "[[0.99841355 0.         0.        ]\n",
      " [1.22736474 0.         0.        ]\n",
      " [0.76946235 0.         0.        ]\n",
      " [1.38016444 0.         0.        ]]\n",
      "\n",
      "Saída final da rede (a2):\n",
      "[[0.50394169]\n",
      " [0.50484552]\n",
      " [0.50303782]\n",
      " [0.50544872]]\n"
     ]
    }
   ],
   "source": [
    "# Funções de ativação\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# (X, W1, b1, W2, b2 já devem ter sido definidos no passo anterior)\n",
    "\n",
    "# Forward propagation\n",
    "# 1. Cálculo na camada oculta\n",
    "z1 = np.dot(X, W1) + b1        # Produto dos dados de entrada pelos pesos + bias da camada oculta\n",
    "a1 = relu(z1)                  # Aplicação da função de ativação ReLU\n",
    "\n",
    "# 2. Cálculo na camada de saída\n",
    "z2 = np.dot(a1, W2) + b2       # Produto da saída da camada oculta pelos pesos + bias da camada de saída\n",
    "a2 = sigmoid(z2)               # Aplicação da função de ativação Sigmoid para gerar a saída final\n",
    "\n",
    "# Resultado\n",
    "print(\"Saída da camada oculta (a1):\")\n",
    "print(a1)\n",
    "print(\"\\nSaída final da rede (a2):\")\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed5b8d",
   "metadata": {},
   "source": [
    "### Passo 3: Calcular o erro\n",
    "\n",
    "Nesta etapa, podem ser utilizados os métodos **Erro Quadrático Médio (MSE)** ou a **Entropia Cruzada (Cross-Entropy)**. Para fins didáticos, usaremos o MSE. \n",
    "\n",
    "- O MSE mede o quão longe as previsões da rede estão dos valores corretos;\n",
    "- Ele calcula a diferença entre a resposta correta (rótulo) e a resposta da rede (previsão);\n",
    "- Essa diferença é elevada ao quadrado (para não ter número negativo) e depois tira a média de todas as diferenças.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fd3d46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Erro (MSE) atual: 0.247220\n"
     ]
    }
   ],
   "source": [
    "# Função para calcular o erro quadrático médio (MSE)\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Cálculo do erro\n",
    "loss = mean_squared_error(y, a2)\n",
    "\n",
    "print(f\"\\nErro (MSE) atual: {loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cff1aa",
   "metadata": {},
   "source": [
    "### Passo 4: Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "533b7054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradiente dW2:\n",
      "[[-0.34958632]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "\n",
      "Gradiente db2:\n",
      "[[-0.24565219]]\n",
      "\n",
      "Gradiente dW1:\n",
      "[[-0.00737945  0.          0.        ]\n",
      " [-0.36007549  0.          0.        ]]\n",
      "\n",
      "Gradiente db1:\n",
      "[[-0.00387937  0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Derivadas das funções de ativação\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "# Backward propagation\n",
    "\n",
    "# 1. Derivada do erro em relação à saída (a2)\n",
    "# Para MSE: dL/da2 = (a2 - y)\n",
    "d_loss_a2 = (a2 - y)\n",
    "\n",
    "# 2. Derivada em relação a z2 (entrada da camada de saída)\n",
    "dz2 = d_loss_a2 * sigmoid_derivative(z2)\n",
    "\n",
    "# 3. Derivadas dos pesos e bias da camada de saída\n",
    "dW2 = np.dot(a1.T, dz2)  # Gradiente dos pesos W2\n",
    "db2 = np.sum(dz2, axis=0, keepdims=True)  # Gradiente do bias b2\n",
    "\n",
    "# 4. Derivada em relação a a1 (saída da camada oculta)\n",
    "d_a1 = np.dot(dz2, W2.T)\n",
    "\n",
    "# 5. Derivada em relação a z1 (entrada da camada oculta)\n",
    "dz1 = d_a1 * relu_derivative(z1)\n",
    "\n",
    "# 6. Derivadas dos pesos e bias da camada oculta\n",
    "dW1 = np.dot(X.T, dz1)  # Gradiente dos pesos W1\n",
    "db1 = np.sum(dz1, axis=0, keepdims=True)  # Gradiente do bias b1\n",
    "\n",
    "# Mostrar os gradientes (opcional, para entender)\n",
    "print(\"Gradiente dW2:\")\n",
    "print(dW2)\n",
    "print(\"\\nGradiente db2:\")\n",
    "print(db2)\n",
    "print(\"\\nGradiente dW1:\")\n",
    "print(dW1)\n",
    "print(\"\\nGradiente db1:\")\n",
    "print(db1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc6d50d",
   "metadata": {},
   "source": [
    "### Passo 5: Loop de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeb4de2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 0 - Erro (MSE): 0.247220\n",
      "Época 100 - Erro (MSE): 0.155880\n",
      "Época 200 - Erro (MSE): 0.154595\n",
      "Época 300 - Erro (MSE): 0.153306\n",
      "Época 400 - Erro (MSE): 0.152011\n",
      "Época 500 - Erro (MSE): 0.150712\n",
      "Época 600 - Erro (MSE): 0.149407\n",
      "Época 700 - Erro (MSE): 0.148096\n",
      "Época 800 - Erro (MSE): 0.146779\n",
      "Época 900 - Erro (MSE): 0.145455\n",
      "\n",
      "Saída final da rede após treinamento:\n",
      "[[0.74553067]\n",
      " [0.80803484]\n",
      " [0.6709623 ]\n",
      " [0.84268967]]\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmetros\n",
    "learning_rate = 0.01\n",
    "epochs = 1000  # Número de vezes que a rede vai treinar\n",
    "\n",
    "# Loop de treinamento\n",
    "for epoch in range(epochs):\n",
    "    # --- Forward propagation ---\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    \n",
    "    # --- Cálculo do erro ---\n",
    "    loss = mean_squared_error(y, a2)\n",
    "    \n",
    "    # --- Backward propagation ---\n",
    "    d_loss_a2 = (a2 - y)\n",
    "    dz2 = d_loss_a2 * sigmoid_derivative(z2)\n",
    "    dW2 = np.dot(a1.T, dz2)\n",
    "    db2 = np.sum(dz2, axis=0, keepdims=True)\n",
    "    \n",
    "    d_a1 = np.dot(dz2, W2.T)\n",
    "    dz1 = d_a1 * relu_derivative(z1)\n",
    "    dW1 = np.dot(X.T, dz1)\n",
    "    db1 = np.sum(dz1, axis=0, keepdims=True)\n",
    "    \n",
    "    # --- Atualização dos pesos e bias ---\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    \n",
    "    # --- Mostrar o erro a cada 100 épocas ---\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Época {epoch} - Erro (MSE): {loss:.6f}\")\n",
    "\n",
    "# Mostrar a saída final da rede após o treinamento\n",
    "print(\"\\nSaída final da rede após treinamento:\")\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d80d327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classificação final (0 = não atleta, 1 = atleta):\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Comparação previsão x realidade:\n",
      "\n",
      "Exemplo 1: Previsto = 1 | Real = 1 | ✅ Acertou\n",
      "Exemplo 2: Previsto = 1 | Real = 1 | ✅ Acertou\n",
      "Exemplo 3: Previsto = 1 | Real = 0 | ❌ Errou\n",
      "Exemplo 4: Previsto = 1 | Real = 1 | ✅ Acertou\n"
     ]
    }
   ],
   "source": [
    "# Threshold (limiar) para classificar\n",
    "threshold = 0.5\n",
    "\n",
    "# Classificação: 1 se >= 0.5, senão 0\n",
    "classificacao = (a2 >= threshold).astype(int)\n",
    "\n",
    "# Exibir resultados\n",
    "print(\"\\nClassificação final (0 = não atleta, 1 = atleta):\")\n",
    "print(classificacao)\n",
    "\n",
    "# Comparação\n",
    "print(\"Comparação previsão x realidade:\\n\")\n",
    "for i in range(len(y)):\n",
    "    print(f\"Exemplo {i+1}: Previsto = {classificacao[i][0]} | Real = {y[i][0]} | {'✅ Acertou' if classificacao[i][0] == y[i][0] else '❌ Errou'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683fcf1",
   "metadata": {},
   "source": [
    "#### O que isso significa?\n",
    "- O modelo não aprendeu perfeitamente.\n",
    "- Há um erro residual (uma pequena quantidade de erro ainda ficou no modelo).\n",
    "- Isso é normal em redes simples ou em casos com poucos dados!\n",
    "- A rede não conseguiu separar 100% os exemplos corretos.\n",
    "\n",
    "#### Possíveis causas\n",
    "- Poucos dados: só 4 exemplos de treinamento. Redes neurais precisam de muitos dados para generalizar bem;\n",
    "- Rede muito simples: só uma camada oculta pequena (3 neurônios);\n",
    "- Épocas insuficientes: talvez precisasse de mais tempo de treinamento;\n",
    "- Dados muito próximos: altura e peso da Pessoa 3 podem ser parecidos com de atletas; \n",
    "- Aprendizado raso: usamos MSE como função de erro - para classificação binária, entropia cruzada seria melhor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b04832f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "def1b450",
   "metadata": {},
   "source": [
    "# Atualização do Modelo Acima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd8857",
   "metadata": {},
   "source": [
    "### Passo 0: dados e rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b26fd17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplos de X (altura, peso):\n",
      "[[ 1.65239108 91.77867037]\n",
      " [ 1.99247746 70.42698064]\n",
      " [ 1.72689162 99.56951362]\n",
      " [ 1.6591026  77.18685672]\n",
      " [ 1.87379423 79.26489574]]\n",
      "\n",
      "Exemplos de y (rótulos):\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fixar a semente para reprodutibilidade\n",
    "np.random.seed(42)\n",
    "\n",
    "# Gerar dados para atletas (altura entre 1.75 e 2.00 metros, peso entre 65 e 85 kg)\n",
    "altura_atleta = np.random.uniform(1.75, 2.00, 50)\n",
    "peso_atleta = np.random.uniform(65, 85, 50)\n",
    "\n",
    "# Gerar dados para não atletas (altura entre 1.50 e 1.75 metros, peso entre 70 e 100 kg)\n",
    "altura_nao_atleta = np.random.uniform(1.50, 1.75, 50)\n",
    "peso_nao_atleta = np.random.uniform(70, 100, 50)\n",
    "\n",
    "# Juntar os dados\n",
    "altura = np.concatenate((altura_atleta, altura_nao_atleta))\n",
    "peso = np.concatenate((peso_atleta, peso_nao_atleta))\n",
    "\n",
    "# Montar X (entradas)\n",
    "X = np.column_stack((altura, peso))\n",
    "\n",
    "# Montar y (rótulos)\n",
    "# 1 para atletas, 0 para não atletas\n",
    "y = np.array([[1]] * 50 + [[0]] * 50)\n",
    "\n",
    "# Embaralhar os dados (importante!)\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Mostrar amostra\n",
    "print(\"Exemplos de X (altura, peso):\")\n",
    "print(X[:5])\n",
    "\n",
    "print(\"\\nExemplos de y (rótulos):\")\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aaadd9",
   "metadata": {},
   "source": [
    "### Passo 1: Inicializar os pesos e bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0d55665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos W1 (entrada -> camada oculta):\n",
      "[[ 0.00496714 -0.00138264  0.00647689  0.0152303 ]\n",
      " [-0.00234153 -0.00234137  0.01579213  0.00767435]]\n",
      "\n",
      "Bias b1 (camada oculta):\n",
      "[[0. 0. 0. 0.]]\n",
      "\n",
      "Pesos W2 (camada oculta -> saída):\n",
      "[[-0.00469474]\n",
      " [ 0.0054256 ]\n",
      " [-0.00463418]\n",
      " [-0.0046573 ]]\n",
      "\n",
      "Bias b2 (saída):\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "# Fixar a semente para reprodutibilidade\n",
    "np.random.seed(42)\n",
    "\n",
    "# Inicializar pesos e bias\n",
    "\n",
    "# W1: pesos da camada de entrada para a camada oculta\n",
    "# 2 entradas (altura, peso) → 4 neurônios ocultos\n",
    "W1 = np.random.randn(2, 4) * 0.01  # Pequenos valores aleatórios\n",
    "\n",
    "# b1: bias para cada um dos 4 neurônios ocultos\n",
    "b1 = np.zeros((1, 4))\n",
    "\n",
    "# W2: pesos da camada oculta para a camada de saída\n",
    "# 4 neurônios ocultos → 1 saída\n",
    "W2 = np.random.randn(4, 1) * 0.01\n",
    "\n",
    "# b2: bias para a saída\n",
    "b2 = np.zeros((1, 1))\n",
    "\n",
    "# Mostrar os valores iniciais (opcional para conferência)\n",
    "print(\"Pesos W1 (entrada -> camada oculta):\")\n",
    "print(W1)\n",
    "\n",
    "print(\"\\nBias b1 (camada oculta):\")\n",
    "print(b1)\n",
    "\n",
    "print(\"\\nPesos W2 (camada oculta -> saída):\")\n",
    "print(W2)\n",
    "\n",
    "print(\"\\nBias b2 (saída):\")\n",
    "print(b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c368c93c",
   "metadata": {},
   "source": [
    "### Passo 2: Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5657f100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saída da camada oculta (a1):\n",
      "[[0.         0.         1.46008287 0.7295078 ]\n",
      " [0.         0.         1.12509695 0.57082713]\n",
      " [0.         0.         1.5835994  0.7904321 ]\n",
      " [0.         0.         1.22969055 0.61762737]\n",
      " [0.         0.         1.26389774 0.63684478]\n",
      " [0.         0.         1.20952637 0.60948069]\n",
      " [0.         0.         1.31915035 0.66426644]\n",
      " [0.         0.         1.41681316 0.70944746]\n",
      " [0.         0.         1.30092137 0.65585557]\n",
      " [0.         0.         1.18431926 0.5946059 ]\n",
      " [0.         0.         1.19846439 0.60182046]\n",
      " [0.         0.         1.2313187  0.61943165]\n",
      " [0.         0.         1.16061704 0.58522086]\n",
      " [0.         0.         1.05308092 0.53471619]\n",
      " [0.         0.         1.41498899 0.70623966]\n",
      " [0.         0.         1.18768116 0.59964034]\n",
      " [0.         0.         1.0721989  0.54274937]\n",
      " [0.         0.         1.29977924 0.65236529]\n",
      " [0.         0.         1.43426232 0.71635837]\n",
      " [0.         0.         1.28418223 0.64807828]\n",
      " [0.         0.         1.12684837 0.56929769]\n",
      " [0.         0.         1.19485732 0.60379938]\n",
      " [0.         0.         1.27742509 0.64016293]\n",
      " [0.         0.         1.15896595 0.58324894]\n",
      " [0.         0.         1.55344479 0.77339875]\n",
      " [0.         0.         1.26934575 0.6403683 ]\n",
      " [0.         0.         1.39598133 0.69814487]\n",
      " [0.         0.         1.14172257 0.57811559]\n",
      " [0.         0.         1.54255497 0.7692467 ]\n",
      " [0.         0.         1.54064038 0.7675748 ]\n",
      " [0.         0.         1.33574189 0.67247354]\n",
      " [0.         0.         1.34466544 0.67573027]\n",
      " [0.         0.         1.04004005 0.52744553]\n",
      " [0.         0.         1.23496307 0.62180301]\n",
      " [0.         0.         1.42836422 0.71322878]\n",
      " [0.         0.         1.23024499 0.61672744]\n",
      " [0.         0.         1.27816686 0.64238711]\n",
      " [0.         0.         1.31141143 0.66027398]\n",
      " [0.         0.         1.28174615 0.64480432]\n",
      " [0.         0.         1.48509233 0.7406618 ]\n",
      " [0.         0.         1.2687568  0.63863046]\n",
      " [0.         0.         1.2388945  0.62302597]\n",
      " [0.         0.         1.53551713 0.76448005]\n",
      " [0.         0.         1.32924259 0.66757522]\n",
      " [0.         0.         1.15200086 0.58276107]\n",
      " [0.         0.         1.46029152 0.72800042]\n",
      " [0.         0.         1.47721554 0.73827458]\n",
      " [0.         0.         1.2165705  0.61509662]\n",
      " [0.         0.         1.22264801 0.61261501]\n",
      " [0.         0.         1.04673657 0.53146874]\n",
      " [0.         0.         1.37933671 0.69055067]\n",
      " [0.         0.         1.3214168  0.66510935]\n",
      " [0.         0.         1.06206856 0.53857281]\n",
      " [0.         0.         1.54099665 0.76850582]\n",
      " [0.         0.         1.22691777 0.61784949]\n",
      " [0.         0.         1.43747722 0.71912007]\n",
      " [0.         0.         1.20342889 0.60690513]\n",
      " [0.         0.         1.06204199 0.53880847]\n",
      " [0.         0.         1.35829039 0.67915998]\n",
      " [0.         0.         1.13592734 0.57283592]\n",
      " [0.         0.         1.50317467 0.7501745 ]\n",
      " [0.         0.         1.05943377 0.53885393]\n",
      " [0.         0.         1.3703035  0.68647837]\n",
      " [0.         0.         1.2817462  0.6446258 ]\n",
      " [0.         0.         1.44383017 0.7222393 ]\n",
      " [0.         0.         1.41559207 0.70695459]\n",
      " [0.         0.         1.54551873 0.76927986]\n",
      " [0.         0.         1.2806669  0.64058887]\n",
      " [0.         0.         1.07449447 0.54344685]\n",
      " [0.         0.         1.10081162 0.55651699]\n",
      " [0.         0.         1.22811885 0.61563232]\n",
      " [0.         0.         1.55896436 0.77573997]\n",
      " [0.         0.         1.16083144 0.58514944]\n",
      " [0.         0.         1.08282538 0.54827405]\n",
      " [0.         0.         1.26843962 0.63696313]\n",
      " [0.         0.         1.06586663 0.5392892 ]\n",
      " [0.         0.         1.10112514 0.55886444]\n",
      " [0.         0.         1.34999534 0.67806873]\n",
      " [0.         0.         1.17370064 0.59308776]\n",
      " [0.         0.         1.28272137 0.64634476]\n",
      " [0.         0.         1.15084459 0.58105107]\n",
      " [0.         0.         1.27624558 0.63918928]\n",
      " [0.         0.         1.20383212 0.60370237]\n",
      " [0.         0.         1.14243989 0.57652181]\n",
      " [0.         0.         1.07579344 0.54430642]\n",
      " [0.         0.         1.28987582 0.64582787]\n",
      " [0.         0.         1.18114376 0.59365597]\n",
      " [0.         0.         1.13760791 0.57689404]\n",
      " [0.         0.         1.34787281 0.67467309]\n",
      " [0.         0.         1.51231151 0.75567995]\n",
      " [0.         0.         1.16928359 0.58702051]\n",
      " [0.         0.         1.29204053 0.65061041]\n",
      " [0.         0.         1.26181699 0.63571549]\n",
      " [0.         0.         1.36668239 0.68337598]\n",
      " [0.         0.         1.53136264 0.76332546]\n",
      " [0.         0.         1.23934882 0.62371424]\n",
      " [0.         0.         1.14183859 0.57847502]\n",
      " [0.         0.         1.12447398 0.56728072]\n",
      " [0.         0.         1.42119292 0.70945604]\n",
      " [0.         0.         1.29597353 0.65204323]]\n",
      "\n",
      "Saída final da rede (a2):\n",
      "[[0.49745907]\n",
      " [0.49803191]\n",
      " [0.49724504]\n",
      " [0.49785624]\n",
      " [0.49779424]\n",
      " [0.49788909]\n",
      " [0.4976983 ]\n",
      " [0.49753255]\n",
      " [0.49772921]\n",
      " [0.49793561]\n",
      " [0.49791082]\n",
      " [0.49785226]\n",
      " [0.497974  ]\n",
      " [0.49815738]\n",
      " [0.4975384 ]\n",
      " [0.49792585]\n",
      " [0.49812588]\n",
      " [0.4977346 ]\n",
      " [0.49750429]\n",
      " [0.49775766]\n",
      " [0.49803166]\n",
      " [0.4979127 ]\n",
      " [0.4977747 ]\n",
      " [0.49797821]\n",
      " [0.4972998 ]\n",
      " [0.49778382]\n",
      " [0.49756985]\n",
      " [0.49800416]\n",
      " [0.49731725]\n",
      " [0.49732142]\n",
      " [0.49766952]\n",
      " [0.49765539]\n",
      " [0.49818096]\n",
      " [0.49784527]\n",
      " [0.49751477]\n",
      " [0.49785665]\n",
      " [0.49777125]\n",
      " [0.49771191]\n",
      " [0.49776429]\n",
      " [0.49741711]\n",
      " [0.49778653]\n",
      " [0.4978393 ]\n",
      " [0.49733096]\n",
      " [0.49768276]\n",
      " [0.49798684]\n",
      " [0.49746058]\n",
      " [0.49742901]\n",
      " [0.49787439]\n",
      " [0.49787024]\n",
      " [0.49816852]\n",
      " [0.49759797]\n",
      " [0.49769469]\n",
      " [0.49814248]\n",
      " [0.49731992]\n",
      " [0.4978592 ]\n",
      " [0.49749735]\n",
      " [0.49789915]\n",
      " [0.49814224]\n",
      " [0.49763562]\n",
      " [0.49801702]\n",
      " [0.49738508]\n",
      " [0.49814521]\n",
      " [0.49761318]\n",
      " [0.4977645 ]\n",
      " [0.49748636]\n",
      " [0.49753687]\n",
      " [0.49731378]\n",
      " [0.49777045]\n",
      " [0.49812241]\n",
      " [0.4980767 ]\n",
      " [0.49786039]\n",
      " [0.49729068]\n",
      " [0.49797383]\n",
      " [0.49810714]\n",
      " [0.49778884]\n",
      " [0.49813725]\n",
      " [0.49807361]\n",
      " [0.4976465 ]\n",
      " [0.49794968]\n",
      " [0.49776137]\n",
      " [0.49799017]\n",
      " [0.4977772 ]\n",
      " [0.49790241]\n",
      " [0.49800519]\n",
      " [0.49811991]\n",
      " [0.49775368]\n",
      " [0.4979404 ]\n",
      " [0.49801035]\n",
      " [0.49765291]\n",
      " [0.49736809]\n",
      " [0.49796186]\n",
      " [0.49774561]\n",
      " [0.49779796]\n",
      " [0.49762098]\n",
      " [0.49733712]\n",
      " [0.49783797]\n",
      " [0.49800361]\n",
      " [0.49803676]\n",
      " [0.49752747]\n",
      " [0.49773938]]\n"
     ]
    }
   ],
   "source": [
    "# Funções de ativação\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# (X, W1, b1, W2, b2 já devem ter sido definidos no passo anterior)\n",
    "\n",
    "# Forward propagation\n",
    "# 1. Cálculo na camada oculta\n",
    "z1 = np.dot(X, W1) + b1        # Produto dos dados de entrada pelos pesos + bias da camada oculta\n",
    "a1 = relu(z1)                  # Aplicação da função de ativação ReLU\n",
    "\n",
    "# 2. Cálculo na camada de saída\n",
    "z2 = np.dot(a1, W2) + b2       # Produto da saída da camada oculta pelos pesos + bias da camada de saída\n",
    "a2 = sigmoid(z2)               # Aplicação da função de ativação Sigmoid para gerar a saída final\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Saída da camada oculta (a1):\")\n",
    "print(a1)\n",
    "\n",
    "print(\"\\nSaída final da rede (a2):\")\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d271627",
   "metadata": {},
   "source": [
    "### Passo 3: Calcular o erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c7b231b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Erro (Entropia Cruzada) atual: 0.692874\n"
     ]
    }
   ],
   "source": [
    "# Função para calcular entropia cruzada\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    epsilon = 1e-15  # Pequeno valor para evitar log(0)\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Garante que y_pred esteja entre (0,1)\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "# Cálculo do erro\n",
    "loss = cross_entropy_loss(y, a2)\n",
    "\n",
    "# Mostrar o erro\n",
    "print(f\"\\nErro (Entropia Cruzada) atual: {loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e770696",
   "metadata": {},
   "source": [
    "### Passo 4: Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e33ffcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradiente dW2:\n",
      "[[0.        ]\n",
      " [0.        ]\n",
      " [0.03870161]\n",
      " [0.01803009]]\n",
      "\n",
      "Gradiente db2:\n",
      "[[-0.00222799]]\n",
      "\n",
      "Gradiente dW1:\n",
      "[[ 0.          0.          0.00029814  0.00029963]\n",
      " [ 0.          0.         -0.01147921 -0.01153648]]\n",
      "\n",
      "Gradiente db1:\n",
      "[[0.00000000e+00 0.00000000e+00 1.03249112e-05 1.03764237e-05]]\n"
     ]
    }
   ],
   "source": [
    "# Backward propagation\n",
    "\n",
    "# 1. Derivada do erro em relação à saída a2\n",
    "# (já é simplificado para Cross-Entropy com Sigmoid)\n",
    "d_loss_a2 = a2 - y\n",
    "\n",
    "# 2. Derivadas dos pesos e bias da camada de saída\n",
    "dW2 = np.dot(a1.T, d_loss_a2) / X.shape[0]  # Normaliza pela quantidade de exemplos\n",
    "db2 = np.sum(d_loss_a2, axis=0, keepdims=True) / X.shape[0]\n",
    "\n",
    "# 3. Derivada em relação a saída da camada oculta (a1)\n",
    "d_a1 = np.dot(d_loss_a2, W2.T)\n",
    "\n",
    "# 4. Derivada em relação a z1 (entrada da camada oculta)\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "dz1 = d_a1 * relu_derivative(z1)\n",
    "\n",
    "# 5. Derivadas dos pesos e bias da camada oculta\n",
    "dW1 = np.dot(X.T, dz1) / X.shape[0]  # Normaliza pela quantidade de exemplos\n",
    "db1 = np.sum(dz1, axis=0, keepdims=True) / X.shape[0]\n",
    "\n",
    "# Mostrar os gradientes (opcional para estudo)\n",
    "print(\"Gradiente dW2:\")\n",
    "print(dW2)\n",
    "\n",
    "print(\"\\nGradiente db2:\")\n",
    "print(db2)\n",
    "\n",
    "print(\"\\nGradiente dW1:\")\n",
    "print(dW1)\n",
    "\n",
    "print(\"\\nGradiente db1:\")\n",
    "print(db1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0813ca1f",
   "metadata": {},
   "source": [
    "### Passo 5: Loop de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "659c7241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 0 - Erro (Cross-Entropy): 0.692874\n",
      "Época 100 - Erro (Cross-Entropy): 0.680755\n",
      "Época 200 - Erro (Cross-Entropy): 0.673913\n",
      "Época 300 - Erro (Cross-Entropy): 0.673947\n",
      "Época 400 - Erro (Cross-Entropy): 0.671096\n",
      "Época 500 - Erro (Cross-Entropy): 0.685659\n",
      "Época 600 - Erro (Cross-Entropy): 0.718397\n",
      "Época 700 - Erro (Cross-Entropy): 0.724689\n",
      "Época 800 - Erro (Cross-Entropy): 0.694257\n",
      "Época 900 - Erro (Cross-Entropy): 0.698852\n",
      "\n",
      "Saída final da rede após o treinamento (a2):\n",
      "[[0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]\n",
      " [0.50436836]]\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmetros\n",
    "learning_rate = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "# Loop de treinamento\n",
    "for epoch in range(epochs):\n",
    "    # --- Forward propagation ---\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    \n",
    "    # --- Cálculo do erro (Cross-Entropy) ---\n",
    "    loss = cross_entropy_loss(y, a2)\n",
    "    \n",
    "    # --- Backward propagation ---\n",
    "    d_loss_a2 = a2 - y\n",
    "    dW2 = np.dot(a1.T, d_loss_a2) / X.shape[0]\n",
    "    db2 = np.sum(d_loss_a2, axis=0, keepdims=True) / X.shape[0]\n",
    "    d_a1 = np.dot(d_loss_a2, W2.T)\n",
    "    dz1 = d_a1 * relu_derivative(z1)\n",
    "    dW1 = np.dot(X.T, dz1) / X.shape[0]\n",
    "    db1 = np.sum(dz1, axis=0, keepdims=True) / X.shape[0]\n",
    "    \n",
    "    # --- Atualização dos pesos e bias ---\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    \n",
    "    # --- Exibir o erro a cada 100 épocas ---\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Época {epoch} - Erro (Cross-Entropy): {loss:.6f}\")\n",
    "\n",
    "# Mostrar a saída final da rede após o treinamento\n",
    "print(\"\\nSaída final da rede após o treinamento (a2):\")\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d735df1d",
   "metadata": {},
   "source": [
    "### Teste com o novo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e813889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descobrir_atleta(pessoas):\n",
    "    # Normalizar os novos dados\n",
    "    # Usar a mesma média e desvio padrão dos dados de treino\n",
    "    mean_X = X.mean(axis=0)\n",
    "    std_X = X.std(axis=0)\n",
    "    pessoas_normalizadas = (pessoas - mean_X) / std_X\n",
    "\n",
    "    # Forward propagation nos novos dados\n",
    "    z1_novos = np.dot(pessoas_normalizadas, W1) + b1\n",
    "    a1_novos = relu(z1_novos)\n",
    "    z2_novos = np.dot(a1_novos, W2) + b2\n",
    "    a2_novos = sigmoid(z2_novos)\n",
    "\n",
    "    # Classificar como atleta (1) ou não (0)\n",
    "    threshold = 0.5\n",
    "    classificacao_novos = (a2_novos >= threshold).astype(int)\n",
    "\n",
    "    # Mostrar resultados\n",
    "    print(\"Probabilidades previstas para novas pessoas:\")\n",
    "    print(a2_novos)\n",
    "\n",
    "    print(\"\\nClassificação final para novas pessoas (0 = não atleta, 1 = atleta):\")\n",
    "    print(classificacao_novos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8b76150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades previstas para novas pessoas:\n",
      "[[0.50425725]\n",
      " [0.49864281]\n",
      " [0.50425375]\n",
      " [0.50425916]]\n",
      "\n",
      "Classificação final para novas pessoas (0 = não atleta, 1 = atleta):\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# Novos dados (altura, peso)\n",
    "pessoas = np.array([\n",
    "    [1.78, 75],  # Pessoa 1\n",
    "    [1.60, 80],  # Pessoa 2\n",
    "    [1.85, 68],  # Pessoa 3\n",
    "    [1.70, 90]   # Pessoa 4\n",
    "])\n",
    "\n",
    "descobrir_atleta(pessoas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77439c8",
   "metadata": {},
   "source": [
    "# Desafio\n",
    "\n",
    "Construa MLPs para os seguintes cenários:\n",
    "- Identificar se um e-mail é spam ou não (classificação binária). Features:\n",
    "    - número de palavras,\n",
    "\t- presença de palavras-chave como \"promoção\", \"grátis\",\n",
    "\t- quantidade de links,\n",
    "\t- tamanho do e-mail.\n",
    "- Classificar pacientes como \"em risco\" ou \"não em risco\" baseado em exames médicos. Features: \n",
    "\t- Com base em dados médicos fictícios:\n",
    "\t- pressão arterial,\n",
    "\t- colesterol,\n",
    "\t- glicemia,\n",
    "\t- idade,\n",
    "\t- IMC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c4b6b9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
